# -*- coding: utf-8 -*-
"""HR Analytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12iJ0insVZO6YUiGiHL_mBfW-tgux8AA4
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import OrdinalEncoder
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import train_test_split

from xgboost import XGBClassifier
from catboost import CatBoostClassifier
from lightgbm import LGBMClassifier

from matplotlib import ticker
import time
import warnings
pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)
pd.set_option('float_format', '{:f}'.format)
warnings.filterwarnings('ignore')


RANDOM_STATE = 12
FOLDS = 5

!pip install catboost lightgbm xgboost

"""Data Loding and Preparation"""

train = pd.read_csv("/content/WA_Fn-UseC_-HR-Employee-Attrition.csv")
test = pd.read_csv("/content/WA_Fn-UseC_-HR-Employee-Attrition.csv")
submission = pd.read_csv("/content/WA_Fn-UseC_-HR-Employee-Attrition.csv")

"""Exploring Train Data"""

train.head()

print(f'\033[92mNumber of rows in train data: {train.shape[0]}')
print(f'\033[94mNumber of columns in train data: {train.shape[1]}')
print(f'\033[91mNumber of values in train data: {train.count().sum()}')
print(f'\033[91mNumber missing values in train data: {sum(train.isna().sum())}')

"""Basic Statistics of Training Data"""

train.describe()

"""Exploring Test data"""

test.head()

print(f'\033[92mNumber of rows in test data: {test.shape[0]}')
print(f'\033[94mNumber of columns in test data: {test.shape[1]}')
print(f'\033[91mNumber of values in train data: {test.count().sum()}')
print(f'\033[91mNo of rows with missing values  in test data: {sum(test.isna().sum())}')

"""Basic Statistics of test data"""

test.describe()

"""EDA"""

TARGET = 'Attrition'
FEATURES = [col for col in train.columns if col != TARGET]

print("Target:", TARGET)
print("Number of features:", len(FEATURES))

train.iloc[:, :-1].describe().T.sort_values(by='std' , ascending = False)\
                     .style.background_gradient(cmap='GnBu')\
                     .bar(subset=["max"], color='#F8766D')\
                     .bar(subset=["mean",], color='#00BFC4')

"""Continuous and Categorical Data Distribution"""

df = pd.concat([train[FEATURES], test[FEATURES]], axis=0)

cat_features = [col for col in FEATURES if df[col].nunique() < 25]
cont_features = [col for col in FEATURES if df[col].nunique() >= 25]

del df
print(f'Total number of features: {len(FEATURES)}')
print(f'\033[92mNumber of categorical (<25 Unique Values) features: {len(cat_features)}')
print(f'\033[96mNumber of continuos features: {len(cont_features)}')


plt.pie([len(cat_features), len(cont_features)],
        labels=['Categorical(<25 Unique Values)', 'Continuos'],
        colors=['#F8766D', '#00BFC4'],
        textprops={'fontsize': 13},
        autopct='%1.1f%%')
plt.show()

"""Feature Distribution of Continous Features"""

ncols = 4
nrows = 2

fig, axes = plt.subplots(nrows, ncols, figsize=(18, 15))

for r in range(nrows):
    for c in range(ncols):
        col = cont_features[r*ncols+c]
        sns.kdeplot(x=train[col], ax=axes[r, c], color='#F8766D', label='Train data' , fill =True )
        sns.kdeplot(x=test[col], ax=axes[r, c], color='#00BFC4', label='Test data', fill =True)
        axes[r,c].legend()
        axes[r, c].set_ylabel('')
        axes[r, c].set_xlabel(col, fontsize=8)
        axes[r, c].tick_params(labelsize=5, width=0.5)
        axes[r, c].xaxis.offsetText.set_fontsize(6)
        axes[r, c].yaxis.offsetText.set_fontsize(4)
plt.show()

"""Feature Distribution of Categorical Features"""

import pandas as pd
import plotly.express as px   # ✅ import px

# Load your dataset into 'data'
data = pd.read_csv("/content/WA_Fn-UseC_-HR-Employee-Attrition.csv")   # adjust path if needed

# Your original code (unchanged)
plot_df = data.groupby(['Gender','Department'])['Attrition'].value_counts(normalize=True)
plot_df = plot_df.mul(100).rename('Percent').reset_index()
fig = px.bar(plot_df, x="Department", y="Percent", color="Attrition", barmode="group",
            text='Percent', opacity=.75, facet_col="Gender", category_orders={'Attrition': ['Yes', 'No']},
            color_discrete_map={'Yes': '#C02B34','No': '#CDBBA7'})
fig.update_traces(texttemplate='%{text:.3s}%', textposition='outside',
                  marker_line=dict(width=1, color='#28221D'),  width=.4)
fig.update_layout(title_text='Attrition Rates by Department and Gender', yaxis_ticksuffix = '%',
                  paper_bgcolor='#F4F2F0', plot_bgcolor='#F4F2F0',font_color='#28221D',
                  height=500, xaxis=dict(tickangle=30))
fig.update_xaxes(showticklabels=True,tickangle=30,col=2)
fig.update_yaxes(title = "", zeroline=True, zerolinewidth=1, zerolinecolor='#28221D')
fig.show()

"""Target Distribution"""

import pandas as pd
import plotly.express as px

# Load data if not already loaded
try:
    data
except NameError:
    data = pd.read_csv("WA_Fn-UseC_-HR-Employee-Attrition.csv")  # adjust path if needed

TARGET = "Attrition"
if TARGET not in data.columns:
    raise KeyError(f"'{TARGET}' column not found. Available columns: {list(data.columns)}")

# Build count table robustly (guarantees a 'count' column)
target_df = (data[TARGET]
             .value_counts(dropna=False)
             .rename_axis(TARGET)
             .reset_index(name='count'))

# Bar chart
fig = px.bar(
    data_frame=target_df,
    x=TARGET,
    y='count',
    color='count',
    color_continuous_scale='Emrld',
    text='count',
    template='plotly_white'
)
fig.update_traces(textposition='outside')
fig.update_layout(yaxis_title='Count')

# Percentages
total = len(data)
for _, row in target_df.iterrows():
    pct = (row['count'] * 100.0) / total
    print(f"\033[94mPercentage of {row[TARGET]} category  : {pct:.2f} %\033[0m")

fig.show()

"""Data Cleaning and Processing"""

from sklearn.preprocessing import OrdinalEncoder, LabelEncoder

# OrdinalEncoder with handle_unknown
ord_encoder = OrdinalEncoder(handle_unknown="use_encoded_value", unknown_value=-1)

cat_features = [col for col in train.columns if train[col].nunique() <= 25 and col != TARGET]

# Fit on train, transform both train and test
train[cat_features] = pd.DataFrame(
    ord_encoder.fit_transform(train[cat_features]),
    columns=cat_features,
    index=train.index
)

test[cat_features] = pd.DataFrame(
    ord_encoder.transform(test[cat_features]),
    columns=cat_features,
    index=test.index
)

# Encode target
encoder = LabelEncoder()
train[TARGET] = encoder.fit_transform(train[TARGET])
test[TARGET] = encoder.transform(test[TARGET])

for fold, (train_idx, valid_idx) in enumerate(skf.split(train[FEATURES], train[TARGET])):

    print(10 * "=", f"Fold={fold+1}", 10 * "=")
    start_time = time.time()

    X_train, X_valid = train.iloc[train_idx][FEATURES], train.iloc[valid_idx][FEATURES]
    y_train, y_valid = train[TARGET].iloc[train_idx], train[TARGET].iloc[valid_idx]

    model = LGBMClassifier(**lgb_params)
    model.fit(X_train, y_train)   # fixed here ✅

    preds_valid = model.predict_proba(X_valid)[:, 1]
    auc = roc_auc_score(y_valid, preds_valid)
    lgb_scores.append(auc)

    run_time = time.time() - start_time
    print(f"Fold={fold+1}, AUC score: {auc:.2f}, Run Time: {run_time:.2f}s")

    fim = pd.DataFrame(
        index=FEATURES,
        data=model.feature_importances_,
        columns=[f'{fold}_importance']
    )
    lgb_fimp.append(fim)

    test_preds = model.predict_proba(test[FEATURES])[:, 1]
    lgb_predictions += test_preds / FOLDS

print("Mean AUC :", np.mean(lgb_scores))

"""Feature importance for LGBM Classifier"""

lgbm_fis_df = pd.concat(lgb_fimp, axis=1).head(15)
lgbm_fis_df.sort_values('1_importance').plot(kind='barh', figsize=(15, 10),
                                       title='Feature Importance Across Folds')
plt.show()

!pip install catboost
from catboost import CatBoostClassifier

from catboost import CatBoostClassifier   # <-- add this import
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import roc_auc_score
import time
import numpy as np
import pandas as pd

catb_params = {
    "objective": "Logloss",
    "iterations": 5000,
    "eval_metric": "AUC",
    "random_seed": 12
}

catb_predictions = 0
catb_scores = []
catb_fimp = []

skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE)
for fold, (train_idx, valid_idx) in enumerate(skf.split(train[FEATURES], train[TARGET])):

    print(10*"=", f"Fold={fold+1}", 10*"=")
    start_time = time.time()

    X_train, X_valid = train.iloc[train_idx][FEATURES], train.iloc[valid_idx][FEATURES]
    y_train , y_valid = train[TARGET].iloc[train_idx] , train[TARGET].iloc[valid_idx]

    model = CatBoostClassifier(**catb_params)
    model.fit(X_train, y_train, verbose=0)   # suppress logs with verbose=0

    preds_valid = model.predict_proba(X_valid)[:, 1]
    auc = roc_auc_score(y_valid, preds_valid)
    catb_scores.append(auc)
    run_time = time.time() - start_time

    print(f"Fold={fold+1}, AUC score: {auc:.2f}, Run Time: {run_time:.2f}s")
    fim = pd.DataFrame(
        index=FEATURES,
        data=model.feature_importances_,
        columns=[f'{fold}_importance']
    )
    catb_fimp.append(fim)
    test_preds = model.predict_proba(test[FEATURES])[:, 1]
    catb_predictions += test_preds / FOLDS

print("Mean AUC :", np.mean(catb_scores))

pip install pandas

from sklearn.model_selection import StratifiedKFold

# Create stratified K-Fold cross-validator
kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import StratifiedKFold
from catboost import CatBoostClassifier
from sklearn.datasets import load_breast_cancer
data = load_breast_cancer()
X = pd.DataFrame(data.data, columns=data.feature_names)
y = pd.Series(data.target)

kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

catb_fimp = []

for fold, (train_idx, val_idx) in enumerate(kf.split(X, y), 1):
    model = CatBoostClassifier(iterations=100, depth=6, learning_rate=0.1, verbose=0)
    model.fit(X.iloc[train_idx], y.iloc[train_idx],
              eval_set=(X.iloc[val_idx], y.iloc[val_idx]),
              verbose=0)

    fi = pd.DataFrame({
        'feature': X.columns,
        f'{fold}_importance': model.get_feature_importance()
    })
    catb_fimp.append(fi.set_index('feature'))

catb_fis_df = pd.concat(catb_fimp, axis=1)

catb_fis_df["mean_importance"] = catb_fis_df.mean(axis=1)

catb_fis_df.sort_values("mean_importance").tail(15).plot(
    kind='barh',
    figsize=(15, 10),
    title="Feature Importance Across Folds (Mean)"
)

plt.show()